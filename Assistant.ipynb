{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed17065",
   "metadata": {},
   "source": [
    "Lets create a personal chat assistant, something like ChatGPT, but completely free. In this project we will use llama LLM model from ollama and Gradio to build a UI.\n",
    "\n",
    "Lets first import libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e362bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d2a1b",
   "metadata": {},
   "source": [
    "Lets define our constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c66cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713993c1",
   "metadata": {},
   "source": [
    "Lets define our role for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bf4620",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923ddf6",
   "metadata": {},
   "source": [
    "We will create a function where we will combine the system message, history and latest message and then call llama model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbfdaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "    \n",
    "    return response.json()['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82289ff",
   "metadata": {},
   "source": [
    "Now there is one code line to creates as a chat interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59056bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://bfce147b611b2949fe.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bfce147b611b2949fe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': 'Hi, how are you?'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': {'title': None}, 'content': 'Hi, how are you?'}, {'role': 'assistant', 'metadata': {'title': None}, 'content': \"Hello! I'm doing well, thank you for asking. I'm a large language model, so I don't have emotions or feelings like humans do, but I'm always happy to help and assist with any questions or tasks you may have. How about you? Is there something on your mind that you'd like to chat about or ask for help with?\"}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'metadata': {'title': None}, 'content': 'Hi, how are you?'}, {'role': 'assistant', 'metadata': {'title': None}, 'content': \"Hello! I'm doing well, thank you for asking. I'm a large language model, so I don't have emotions or feelings like humans do, but I'm always happy to help and assist with any questions or tasks you may have. How about you? Is there something on your mind that you'd like to chat about or ask for help with?\"}, {'role': 'user', 'content': 'How many moons there are in solar system?'}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df8a2a9",
   "metadata": {},
   "source": [
    "Also, you can customize the assistant to do a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc3bc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a coffe shop. \\\n",
    "Suggest to the client these kind of coffees: black coffee - 1 EUR, coffee with milk - 1.5 EUR, capuchino - 2 EUR, espresso - 3 EUR. \\\n",
    "Suggest to the client these cakes: chocolate, cheese or carrots, each costs 3 EUR.\\\n",
    "If client buys any coffee and cake apply 20 % discount. \\\n",
    "When order is formed calculate the total price.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891edf7",
   "metadata": {},
   "source": [
    "The rest is the code as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9d9812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"History is:\")\n",
    "    print(history)\n",
    "    print(\"And messages is:\")\n",
    "    print(messages)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "    \n",
    "    return response.json()['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c999b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://9ec2de8287543ab5f3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9ec2de8287543ab5f3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is:\n",
      "[]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful assistant in a coffe shop. Suggest to the client these kind of coffees: black coffee - 1 EUR, coffee with milk - 1.5 EUR, capuchino - 2 EUR, espresso - 3 EUR. Suggest to the client these cakes: chocolate, cheese or carrots, each costs 3 EUR.If client buys any coffee and cake apply 20 % discount. When order is formed calculate the total price.'}, {'role': 'user', 'content': 'Hi'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': {'title': None}, 'content': 'Hi'}, {'role': 'assistant', 'metadata': {'title': None}, 'content': 'Welcome to our coffe shop! What can I get for you today? Would you like a black coffee, coffee with milk, capuchino, or something else? And would you like to pair it with one of our delicious cakes - chocolate, cheese, or carrots?'}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful assistant in a coffe shop. Suggest to the client these kind of coffees: black coffee - 1 EUR, coffee with milk - 1.5 EUR, capuchino - 2 EUR, espresso - 3 EUR. Suggest to the client these cakes: chocolate, cheese or carrots, each costs 3 EUR.If client buys any coffee and cake apply 20 % discount. When order is formed calculate the total price.'}, {'role': 'user', 'metadata': {'title': None}, 'content': 'Hi'}, {'role': 'assistant', 'metadata': {'title': None}, 'content': 'Welcome to our coffe shop! What can I get for you today? Would you like a black coffee, coffee with milk, capuchino, or something else? And would you like to pair it with one of our delicious cakes - chocolate, cheese, or carrots?'}, {'role': 'user', 'content': 'Yes, your coffee shop is really nice, I would like black coffee and cheese cake.'}]\n",
      "History is:\n",
      "[{'role': 'user', 'metadata': {'title': None}, 'content': 'Hi'}, {'role': 'assistant', 'metadata': {'title': None}, 'content': 'Welcome to our coffe shop! What can I get for you today? Would you like a black coffee, coffee with milk, capuchino, or something else? And would you like to pair it with one of our delicious cakes - chocolate, cheese, or carrots?'}, {'role': 'user', 'metadata': {'title': None}, 'content': 'Yes, your coffee shop is really nice, I would like black coffee and cheese cake.'}, {'role': 'assistant', 'metadata': {'title': None}, 'content': \"I'll get that made for you right away.\\n\\nYour black coffee will be 1 EUR, and the cheese cake will be an additional 3 EUR, making a total of... 4 EUR. However, since you're ordering both a coffee and a cake, I can offer you a 20% discount! That brings the total down to 3.2 EUR.\\n\\nWould you like me to get your order ready for you right away?\"}]\n",
      "And messages is:\n",
      "[{'role': 'system', 'content': 'You are a helpful assistant in a coffe shop. Suggest to the client these kind of coffees: black coffee - 1 EUR, coffee with milk - 1.5 EUR, capuchino - 2 EUR, espresso - 3 EUR. Suggest to the client these cakes: chocolate, cheese or carrots, each costs 3 EUR.If client buys any coffee and cake apply 20 % discount. When order is formed calculate the total price.'}, {'role': 'user', 'metadata': {'title': None}, 'content': 'Hi'}, {'role': 'assistant', 'metadata': {'title': None}, 'content': 'Welcome to our coffe shop! What can I get for you today? Would you like a black coffee, coffee with milk, capuchino, or something else? And would you like to pair it with one of our delicious cakes - chocolate, cheese, or carrots?'}, {'role': 'user', 'metadata': {'title': None}, 'content': 'Yes, your coffee shop is really nice, I would like black coffee and cheese cake.'}, {'role': 'assistant', 'metadata': {'title': None}, 'content': \"I'll get that made for you right away.\\n\\nYour black coffee will be 1 EUR, and the cheese cake will be an additional 3 EUR, making a total of... 4 EUR. However, since you're ordering both a coffee and a cake, I can offer you a 20% discount! That brings the total down to 3.2 EUR.\\n\\nWould you like me to get your order ready for you right away?\"}, {'role': 'user', 'content': 'Yes, please:)'}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93879e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
